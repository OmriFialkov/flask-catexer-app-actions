name: ci cd with helm

on:
  push:
    paths:
      - 'charts/helm-flask/**'
      - 'app/**'
    branches:
      - main
  pull_request: # works with git diff while contains(github.event.before) is not working.
    paths:
      - 'charts/helm-flask/**'
      - 'app/**'
    branches:
      - main

env:
  IMAGE_NAME: crazyguy888/catexer-actions
  IMAGE_TAG: 0.0.${{ github.run_number }}

jobs:
  Build-Test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3
        with:
          fetch-depth: 3 # shallow clone - fetch last 3 commits specifically instead of last one only - for git diff

      - name: Debug GitHub SHA values
        run: |
          echo "Previous commit (before push): ${{ github.event.before }}"
          echo "Latest commit (new push): ${{ github.sha }}"
      
      - name: Debug Modified Files using Git
        run: |
          echo "Modified files between commits:"
          git diff --name-only ${{ github.event.before }} ${{ github.sha }}
         

      - name: Check If App Dir Changed
        run: | # comparing files differences between 2 last commits to find line starting with "app/"
          if git diff --name-only ${{ github.event.before }} ${{ github.sha }} | grep -q "^app/"; then
            echo "app dir changed"
            echo "APP_MODIFIED=true" >> $GITHUB_ENV
          else
            echo "app dir not changed"
            echo "APP_MODIFIED=false" >> $GITHUB_ENV
          fi

      - name: APP CI - Login to Docker Hub # prepares the environment.
        if: env.APP_MODIFIED == 'true'
        uses: docker/login-action@v2
        with:
          username: ${{ secrets.dockeruser }} # github secrets
          password: ${{ secrets.dockertoken }} # github secrets
      
      - name: APP CI - Set Environment Variables # GITHUB_ENV - just to access them quicker in current job by name only.
        if: env.APP_MODIFIED == 'true'
        run: |
            echo "FLASK_ENV=${{ vars.FLASK_ENV }}" >> $GITHUB_ENV
            echo "MYSQL_HOST=${{ vars.MYSQL_HOST }}" >> $GITHUB_ENV
            echo "MYSQL_USER=${{ vars.MYSQL_USER }}" >> $GITHUB_ENV
            echo "MYSQL_DATABASE=${{ vars.MYSQL_DATABASE }}" >> $GITHUB_ENV
            echo "PORT=${{ vars.PORT }}" >> $GITHUB_ENV
            echo "MYSQL_PASSWORD=${{ secrets.MYSQL_PASSWORD }}" >> $GITHUB_ENV
            echo "MYSQL_ROOT_PASSWORD=${{ secrets.MYSQL_ROOT_PASSWORD }}" >> $GITHUB_ENV
      
      - name: APP CI - Debug Environment Variables
        if: env.APP_MODIFIED == 'true'
        run: |
              echo "IMAGE_NAME=${IMAGE_NAME}"
              echo "IMAGE_TAG=${IMAGE_TAG}"

      - name: APP CI - Build Docker Compose Image # no cache anyway - removed --no-cache in build command.
        if: env.APP_MODIFIED == 'true'
        run: |
            docker compose build
            docker tag ${IMAGE_NAME}:${IMAGE_TAG} ${IMAGE_NAME}:latest
  
      - name: APP CI - Push Docker Image # in the end: need to do push after tests. #####
        if: env.APP_MODIFIED == 'true'
        run: |
            docker images    
            docker push ${IMAGE_NAME}:${IMAGE_TAG}
            docker push ${IMAGE_NAME}:latest

      - name: APP CI - Test - Running Project
        if: env.APP_MODIFIED == 'true'
        run: | # running without pulling nor building flask image because it is already built - docker compose reads the same image name by image context.
            ls
            docker images
            docker compose up -d
            sleep 1
            docker compose ps
      
      - name: APP CI - Run Tests # another tests. bandit etc..... #######
        if: env.APP_MODIFIED == 'true'
        run: |
            sleep 3
            docker compose logs
            echo "port being tested: ${{ env.PORT }}"
            curl -f http://localhost:${{ env.PORT }}
            echo "tests passed.."

      - name: APP CI + HELM CI - Insert Image Tag to My Helm Chart values.yaml
        if: env.APP_MODIFIED == 'true'
        run: |
          echo "updating image tag in values.yaml to ${IMAGE_TAG}"
          cd charts/helm-flask
          sed -i "s/tag: .*/tag: ${IMAGE_TAG}/g" ./values.yaml
          cat ./values.yaml

      - name: Helm CI - Install Helm
        run: |
          curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version

      - name: Helm CI - Update Helm Chart Version
        run: |
          cd charts/helm-flask
          sed -i "s/version: .*/version: 0.0.${{ github.run_number }}/g" ./Chart.yaml
          echo "# this file was modified by a ci to update helm version tagging" >> ./Chart.yaml

      - name: Helm CI - Package Helm Chart
        run: |
          cd charts
          helm package helm-flask --destination ..
          cd ..
          ls -lrta
      
      - name: Helm CI - Update Helm Repo Index
        run: |
          helm repo index --url https://omrifialkov.github.io/helm-flaskgif .
          ls -lrta

      - name: Helm CI - Push Updated Helm Chart
        env:
          HELM_REPO_PAT: ${{ secrets.HELM_REPO_PAT }}
        run: |
          set -x
          git clone https://${HELM_REPO_PAT}@github.com/OmriFialkov/helm-flaskgif.git helmrepo
          cd helmrepo
          ls -lrta
          git config --global user.name "github-actions-app"
          git config --global user.email "github-actions@gmail.com"

          rm -f *.tgz && rm -f index.yaml
          cp ../*.tgz .
          cp ../index.yaml .
          ls -lrta

          git add .
          git commit -m "Updated helm chart version from APP REPO TRIGGER - Version 0.0.${{ github.run_number }}"
          git push origin main
          echo "pushed updated helm chart to helm-repo"
  CD:
    runs-on: ubuntu-latest
    needs: "Build-Test" # run only after this job is successful - if failed - won't run.
    steps:
      - name: Checkout Code
        uses: actions/checkout@v3

      - name: setup Terraform
        uses: hashicorp/setup-terraform@v2
        with: 
          terraform_wrapper: false 

      - name: Configure AWS Credentials # for s3 tf remote state - accessing s3 bucket.
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Setup google cloud service account credentials # env configuring for terraform commands.
        run: | 
          echo '${{ secrets.GCP_SA_KEY }}' | base64 --decode > /tmp/key.json
          echo "GOOGLE_APPLICATION_CREDENTIALS=/tmp/key.json" >> $GITHUB_ENV

      - name: Install gcloud CLI # for cli commands
        uses: google-github-actions/setup-gcloud@v1

      - name: login to gcloud # using service account as a credential to login to gcloud cli.
        run: |
          gcloud auth activate-service-account --key-file=/tmp/key.json

      - name: verify gcloud login # debug.
        run: |
          set -x
          gcloud auth list
          
      - name: Terraform Init
        run: |
          cd google-k8s
          terraform init

      - name: Terraform Apply # update cluster infrastructure.
        run: |
          cd google-k8s
          terraform apply -auto-approve

      - name: Install Helm
        run: |
            curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
            helm version

      - name: Add and Update Helm Repository
        run: |
            echo "$GITHUB_WORKSPACE"
            helm repo add flaskrepo https://omrifialkov.github.io/helm-flaskgif
            helm repo update
            helm search repo flaskrepo --versions

      - name: install GKE google plugin # a must install google plugin to connect to gke cluster
        run: |
            gcloud components install gke-gcloud-auth-plugin

      - name: List GKE Clusters # debug.
        run: |
            gcloud container clusters list --project ${{ secrets.GCP_PROJECT_ID }}
          
      - name: Set GKE Context to connect to cluster # runner is connecting to cluster.
        run: |
            gcloud container clusters get-credentials \
              ${{ secrets.GCP_CLUSTER_NAME }} \
              --project ${{ secrets.GCP_PROJECT_ID }} \
              --zone ${{ secrets.GCP_ZONE }}

      - name: Deploy Flask App Using Helm # Updating Release and App-Image (older with --set flag)
        run: |
          set -ex
          echo "IMAGE_TAG=${IMAGE_TAG}"
          helm upgrade --install release flaskrepo/helm-flask
          helm list

      - name: Verify Monitor Stack Is Up & Running # -q on grep is quiet mode, upgrade can be from values.yaml or published chart itself. ( this script can update both subcharts automatically - except from local chart version increment and kube-prometheus-stack remote files like default values.yaml )
        run: | # works, tested, helm list in the end to make sure whether upgrade took place or not - will go up a revision even if it did not actually upgraded something but the command succeeded, not urgent to upgrade this helm chart separately with triggers.
          set -x
          echo "checking if a conflicting monitoring release exists already in cluster by other release name and cannot be managed.."
          
          existing_release=$(helm list -A -o json | jq -r '.[] | select(.chart | startswith("monitor-stack")) | .name')
          
          if [[ -n "$existing_release" && "$existing_release" != "my-monitoring" ]]; then
            echo "monitor stack already running under release $existing_release, please rename manually to be managed by this workflow."
          
          elif [[ -n "$existing_release" && "$existing_release" == "my-monitoring" ]] || [[ -z "$existing_release" ]]; then
            echo "no conflicting monitoring release exists in cluster, will install / upgrade my-monitoring release"

            cd charts/monitor-stack/
            helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
            helm dependency update .

            if helm list -n monitor | grep -iq "my-monitoring"; then
              echo "release found, will upgrade"

              last_revision=$(helm history my-monitoring -n monitor --max 1 | awk 'NR==2 {print $1}')
              echo "last revision is $last_revision - debugging"

              if ! helm upgrade my-monitoring . -n monitor; then
                echo "upgrade may have failed - initializing rollback and exiting"
                helm rollback my-monitoring $last_revision -n monitor
                exit 1
              fi

              echo "upgrade successful"

            else
              echo "release not found, will install"


              if ! helm install my-monitoring . -n monitor; then
                echo "install may have failed - initializing cleanup and exiting"
                helm uninstall my-monitoring -n monitor
                exit 1
              fi

              echo "install successful"

            fi 

            helm status my-monitoring -n monitor
            
          fi
    

      - name: Verify Logging Stack Is Up & Running # for local subchart files - will be updated with helm upgrade only - sufficient.
        run: |
          set -x
          echo "checking if a conflicting loki-stack release exists already in cluster by other release name and cannot be managed.."

          existing_loki_release=$(helm list -A -o json | jq -r '.[] | select(.chart | startswith("loki-stack")) | .name')

          if [[ -n "$existing_loki_release" && "$existing_loki_release" != "loki" ]]; then
            echo "loki stack already running under release $existing_loki_release, please rename manually to be managed by this workflow."
          
          elif [[ -n "$existing_loki_release" && "$existing_loki_release" == "loki" ]]; then
            echo "upgrading managed-existing loki stack release.."
            helm repo add grafana https://grafana.github.io/helm-charts
            cd charts/log/
            helm upgrade loki grafana/loki-stack \
             -n log -f loki-values.yaml
            
            helm list -n log
            if helm status loki -n log | grep -iq "deployed"; then
              echo "loki upgrade successful"
            else
              echo "loki upgrade may have failed"
              exit 1
            fi

          else
            echo "loki stack release does not exist, installing under name loki.." 
            cd charts/log/ 
            helm repo add grafana https://grafana.github.io/helm-charts
            helm install loki grafana/loki-stack \
             -n log -f loki-values.yaml

            kubectl get pods -n log
            if helm status loki -n log | grep -iq "deployed"; then
              echo "loki install successful"
            else
              echo "loki install may have failed"
              exit 1
            fi
          fi

      - name: cleaning up docker hub older tags
        env:
          DOCKERTOKEN: ${{ secrets.DOCKERTOKEN }}
          DOCKER_USER: ${{ secrets.DOCKER_USER }}
          DOCKER_REPO: ${{ secrets.DOCKER_REPO }}
        run: |
          chmod +x ./cleanups/docker-clean.sh
          ./cleanups/docker-clean.sh




# NOTES:
#____________________________________________________________________________________________________

# --no-build in production environment.
# ${IMAGE_TAG} is referenced from top level env variable IMAGE_TAG up there.
# --set flag overrides default value in values.yaml which is.
# passed to flask deployment in deployment-flask.yaml so image tag is changed everytime - old way.
# when naming workflow yaml name: field in it - probably resets its workflow run number to 1, the github.run_number.
# with 3 helm charts - monitor-stack, logging and flask app.
# dashboards and service monitors are manual - not in values.yaml - additional helm chart.
# IF WE UPDATE THE VALUES.YAML OF THE CHART AND RUN HELM UPGRADE - WILL IT GO UP A REVISION? - YES IT GOES UP A REVISION.

# monitor-stack - remote chart will be updated in this cd if chart's version is updated, local main files can also be updated.

# logging - this local chart will not be updated with helm dependency update but local files and the tepmlate updated with helm upgrade, 
# version of this local chart can be updated only manually in main chart.yaml and chart's chart.yaml.

# helm dependency update use unpacked dir first and then only looks for the tgz if not found in unpacked dir.

# TO DO:
# ____________________________________________________________________________________________________

# fix - all ci cd in one workflow - DONE HERE.
# HELM CHART PACK TO UPDATE: HERE AND NOT IN ANOTHER CI - DONE.